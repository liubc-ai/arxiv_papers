# WISE: A World Knowledge-Informed Semantic Evaluation for Text-to-Image
  Generation

**作者**: Yuwei Niu, Munan Ning, Mengren Zheng, Weiyang Jin, Bin Lin, Peng Jin, Jiaqi Liao, Chaoran Feng, Kunpeng Ning, Bin Zhu, Li Yuan

**发表时间**: 2025-03-10T12:47:53Z

**更新时间**: 2025-05-27T18:05:23Z

**PDF链接**: [http://arxiv.org/pdf/2503.07265v2](http://arxiv.org/pdf/2503.07265v2)

**arXiv ID**: 2503.07265v2

## 摘要

Text-to-Image (T2I) models are capable of generating high-quality artistic
creations and visual content. However, existing research and evaluation
standards predominantly focus on image realism and shallow text-image
alignment, lacking a comprehensive assessment of complex semantic understanding
and world knowledge integration in text to image generation. To address this
challenge, we propose $\textbf{WISE}$, the first benchmark specifically
designed for $\textbf{W}$orld Knowledge-$\textbf{I}$nformed $\textbf{S}$emantic
$\textbf{E}$valuation. WISE moves beyond simple word-pixel mapping by
challenging models with 1000 meticulously crafted prompts across 25 sub-domains
in cultural common sense, spatio-temporal reasoning, and natural science. To
overcome the limitations of traditional CLIP metric, we introduce
$\textbf{WiScore}$, a novel quantitative metric for assessing knowledge-image
alignment. Through comprehensive testing of 20 models (10 dedicated T2I models
and 10 unified multimodal models) using 1,000 structured prompts spanning 25
subdomains, our findings reveal significant limitations in their ability to
effectively integrate and apply world knowledge during image generation,
highlighting critical pathways for enhancing knowledge incorporation and
application in next-generation T2I models. Code and data are available at
https://github.com/PKU-YuanGroup/WISE.
